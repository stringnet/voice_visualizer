// frontend/src/App.jsx (v3)
import React, { useState, useEffect, useRef, useCallback } from 'react';
import Visualizer from './components/Visualizer';
import AudioPlayer from './components/AudioPlayer'; // Importa la v3 de AudioPlayer

function App() {
  const [audioData, setAudioData] = useState(null);
  const [analyser, setAnalyser] = useState(null);
  const [status, setStatus] = useState('‚ö™ Desconectado');
  const [detectedEmotion, setDetectedEmotion] = useState('---');
  const [inputText, setInputText] = useState('');

  const socketRef = useRef(null);
  // --- NUEVO: Ref para el AudioContext y flag para saber si ya intentamos reanudar ---
  const audioCtxRef = useRef(null);
  const audioContextResumed = useRef(false);
  // ------------------------------------------------------------------------------

  // --- Funci√≥n para asignar la ref del AudioContext ---
  // Se la pasaremos a AudioPlayer para que nos d√© la instancia del contexto
  const handleSetAudioContextRef = useCallback((context) => {
     console.log("App.js: Recibida referencia de AudioContext desde AudioPlayer.", context?.state);
     audioCtxRef.current = context;
  }, []);


  // --- Funci√≥n para Enviar Mensajes (Modificada para intentar resume) ---
  const sendMessageToServer = useCallback(async (textPayload) => { // Hacerla async
    // --- NUEVO: Intentar reanudar AudioContext en la primera interacci√≥n ---
    if (audioCtxRef.current && audioCtxRef.current.state === 'suspended' && !audioContextResumed.current) {
      console.log("App.js: Detectada primera interacci√≥n con contexto suspendido. Intentando reanudar...");
      try {
        await audioCtxRef.current.resume();
        console.log("App.js: Resume intentado. Nuevo estado:", audioCtxRef.current.state);
        // Marcar como intentado incluso si falla, para no reintentar innecesariamente.
        // La l√≥gica en AudioPlayer verificar√° si realmente est√° 'running'.
        audioContextResumed.current = true;
        // Opcional: Forzar un re-render o avisar a AudioPlayer si fuera necesario (poco probable)
      } catch (err) {
        console.error("App.js: Error durante audioContext.resume():", err);
        // Informar al usuario podr√≠a ser √∫til aqu√≠ si falla el resume
        alert("No se pudo activar el audio autom√°ticamente. Puede que necesites interactuar m√°s o revisar permisos.");
      }
    }
    // ---------------------------------------------------------------------

    if (socketRef.current?.readyState === WebSocket.OPEN) {
      try {
        const message = JSON.stringify({ text: textPayload });
        socketRef.current.send(message);
        console.log("Mensaje enviado -> Servidor:", textPayload);
        // setStatus("ü§ñ Procesando IA...");
      } catch (error) {
         console.error("Error al enviar mensaje (JSON stringify):", error);
      }
    } else {
      console.warn("WebSocket no conectado al intentar enviar:", textPayload);
      setStatus("‚ö†Ô∏è WebSocket no conectado");
    }
  }, []); // Dependencia vac√≠a


  // --- Conexi√≥n WebSocket y Manejador de Mensajes ---
  useEffect(() => {
    const socket = new WebSocket("wss://backvisualizador.scanmee.io/ws");
    socketRef.current = socket;
    socket.onopen = () => { console.log("üü¢ WebSocket conectado"); setStatus("‚úÖ Conectado"); };
    socket.onclose = (event) => { console.warn("üîå WebSocket cerrado", event.reason); setStatus(`‚ö™ Desconectado (${event.code})`); };
    socket.onerror = (error) => { console.error("‚ùå WebSocket error:", error); setStatus("‚ùå Error de conexi√≥n"); };

    socket.onmessage = (event) => {
      if (event.data instanceof Blob) {
        setStatus("üîä Recibiendo audio...");
        event.data.arrayBuffer().then((buffer) => {
          setAudioData(buffer); // Esto disparar√° el useEffect de AudioPlayer
        }).catch(err => console.error("Error convirtiendo Blob a ArrayBuffer", err));
        setStatus("‚ñ∂Ô∏è Procesando audio..."); // Cambiado de "Reproduciendo"
      }
      else if (typeof event.data === 'string') {
        let parsedData;
        try {
          parsedData = JSON.parse(event.data);
          if (parsedData && typeof parsedData.text === 'string') {
            const receivedText = parsedData.text;
            console.log("Texto recibido <- API/Otro:", receivedText);
            // Iniciar conversaci√≥n reenviando el texto
            // La llamada a sendMessageToServer intentar√° reanudar el contexto si es necesario
            sendMessageToServer(receivedText);
            setStatus("üí¨ Texto recibido, iniciando IA...");
          } else {
            console.warn("Mensaje JSON no reconocido recibido:", parsedData);
          }
        } catch (error) {
          // Mensajes como "[‚úî] Audio generado..." entrar√°n aqu√≠
          console.log("Mensaje de texto plano recibido:", event.data);
           if (event.data.startsWith("[‚úî]")) {
                setStatus("‚úÖ Listo"); // Actualizar estado en √©xito
           } else if (event.data.startsWith("[ERROR]") || event.data.startsWith("[‚ùå]")) {
                setStatus("‚ö†Ô∏è Error Backend"); // Actualizar estado en error
           }
        }
      } else {
        console.log("Tipo de mensaje no manejado recibido:", event.data);
      }
    };

    return () => {
      if (socketRef.current) {
        socketRef.current.close();
        console.log("WebSocket cerrado al desmontar");
      }
    };
  }, [sendMessageToServer]); // sendMessageToServer es dependencia estable

  // --- Manejador para el bot√≥n Enviar ---
  const handleSendText = () => {
    const textToSend = inputText.trim();
    if (textToSend) {
      // sendMessageToServer ahora intentar√° reanudar el contexto si es la primera vez
      sendMessageToServer(textToSend);
      setInputText('');
    } else {
      console.log("Input vac√≠o, no se env√≠a nada.");
    }
  };

  // --- Manejador para tecla Enter ---
   const handleKeyPress = (event) => {
    if (event.key === 'Enter') {
      handleSendText(); // Llama a la misma funci√≥n, que intentar√° reanudar
    }
  };

  // --- Renderizado ---
  return (
    <div style={{ textAlign: 'center', marginTop: '20px' }}>
      <h1>Visualizador IA</h1>
      <Visualizer analyser={analyser} />
      {/* Pasar la funci√≥n para setear la ref del contexto */}
      <AudioPlayer
          audioData={audioData}
          onStreamReady={setAnalyser}
          setAudioContextRef={handleSetAudioContextRef}
      />
      <div style={{ marginTop: '30px' }}>
        <input
          type="text"
          id="textInput"
          placeholder="Haz tu pregunta..."
          value={inputText}
          onChange={(e) => setInputText(e.target.value)}
          onKeyPress={handleKeyPress}
          style={{ padding: '10px', width: '300px' }}
        />
        <button
          onClick={handleSendText} // Este clic es la interacci√≥n clave
          style={{ padding: '10px 20px', marginLeft: '10px' }}
        >
          Enviar
        </button>
      </div>
       {/* Mostrar estado */}
       <div style={{ marginTop: '10px', fontSize: '12px', color: '#555' }}>
           {status}
           {/* Ya no mostramos emoci√≥n aqu√≠, o como prefieras */}
           {/* {detectedEmotion !== '---' && `| Emoci√≥n: ${detectedEmotion}`} */}
       </div>
    </div>
  );
}

export default App;
